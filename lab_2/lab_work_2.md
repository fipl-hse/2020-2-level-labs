# Лабораторная работа №2

## Дано

1. Два текста на английском языке
2. Необходимо посчитать степень заимствований из первого текста во втором тексте.
За основу берется алгоритм поиска наибольшей общей подпоследовательности (longest common subsequence)


## Терминология
Последовательность представляет собой упорядоченный набор элементов. 

Возьмем две последовательности: `x = ['the', 'cat', 'is', 'sleeping']` и `y = ['the', 'dog', 'is', 'running']`

`z` — подпоследовательность `x` в том случае, если существует строго возрастающий набор индексов элементов `x`,
из которых получается `z`. Например, для `x = ['the', 'cat', 'is', 'sleeping']`, `z = ['the', 'sleeping']`.

Общей подпоследовательностью для `x` и `y` считаем такую последовательность `z`,
которая является одновременно подпоследовательностью `x` и подпоследовательностью `y`.

Наибольшая общая подпоследовательность — это общая подпоследовательность с максимальной длиной.
Далее будем использовать сокращение `LCS`.

Например, для `x = ['the', 'cat', 'is', 'sleeping']` и `y = ['the', 'dog', 'is', 'running']`,
`LCS(x, y)= ['the', 'is']`.

## Что надо сделать

В рамках лабораторной работы №2 требуется разработать алгоритм поиска наибольшей общей подпоследовательности
и использовать его для выявления плагиата.


### Шаг 1. Токенизация текста

Функция принимает на вход текст и возвращает кортеж предложений с токенами.

Например, text = 'I have a cat.\nHis name is Bruno'
--> (('i', 'have', 'a', 'cat'), ('his', 'name', 'is', 'bruno'))

**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО импортировать функцию tokenize из модуля tokenizer.

**Интерфейс:**

```py
def tokenize(text: str) -> tuple:
  pass
```


### Шаг 2. Создание матрицы решений

Функция принимает на вход количество строк и столбцов и создает матрицу.
Функция должна возвращать объект типа list - список, состоящий из списков заданного размера.
Все элементы списков - нули.

Например, матрица 2x2 – [[0, 0], [0, 0]]

**Интерфейс:**

```py
def create_zero_matrix(rows: int, columns: int) -> list:
  pass
```

### Шаг 3. Заполнение матрицы решений

На данном шаге применяется алгоритм поиска наибольшей общей подпоследовательности.

Функция принимает на вход два предложения в виде токенов.
Возвращаемым значением является заполненная матрица решений.

Правило заполнения каждой ячейки матрицы:

<img src="https://latex.codecogs.com/gif.latex?LCS(X_i,&space;Y_j)&space;=&space;\left\{\begin{matrix}0&space;&&space;i=0\:&space;or\:&space;j=0\\&space;LCS(X__{i-1},&space;Y_{j-1})&space;&plus;&space;1&space;&&space;i,&space;j>0\:&space;and\:&space;x_i=y_i&space;\\&space;max\left&space;\{LCS(X__{i},&space;Y_{j-1}),&space;LCS(X__{i-1},&space;Y_{j})&space;\right&space;\}&space;&&space;i,&space;j>0\:&space;and\:&space;x_i\neq&space;y_i&space;\end{matrix}\right." title="LCS(X_i, Y_j) = \left\{\begin{matrix}0 & i=0\: or\: j=0\\ LCS(X__{i-1}, Y_{j-1}) + 1 & i, j>0\: and\: x_i=y_i \\ max\left \{LCS(X__{i}, Y_{j-1}), LCS(X__{i-1}, Y_{j}) \right \} & i, j>0\: and\: x_i\neq y_i \end{matrix}\right." />

> Матрица решений из разбора примера в Разделе "Терминология":

|     |    |     |     |     |     |
|---  |---  |---  |  ---|  ---|  ---|
|     |**0**|**the**|**dog**|**is**|**running**|
|**0**|    0|    0|    0|    0|    0|
|**the**|    0|    1|    1|    1|    1|
|**cat**|    0|    1|    1|    1|    1|
|**is**|    0|    1|    1|    2|    2|
|**sleeping**|    0|    1|    1|    2|    2|


**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать функцию create_zero_matrix (см. Шаг 1).

**Интерфейс:**

```py
def fill_lcs_matrix(first_sentence_tokens: tuple, second_sentence_tokens: tuple) -> list:
  pass
```

### Шаг 4. Расчет длины наибольшей общей подпоследовательности (выполнение Шагов 1-3 соответствует 4 баллам)

Функция принимает на вход два предложения в виде токенов.
Возвращаемым значением является число - длина наибольшей общей подпоследовательности.

Длина наибольшей общей подпоследовательности находится на пересечении последней строки и последнего столбца.

|     |    |     |     |     |     |
|---  |---  |---  |  ---|  ---|  ---|
|     |**0**|**the**|**dog**|**is**|**running**|
|**0**|    0|    0|    0|    0|    0|
|**the**|    0|    1|    1|    1|    1|
|**cat**|    0|    1|    1|    1|    1|
|**is**|    0|    1|    1|    2|    2|
|**sleeping**|    0|    1|    1|    2|    **_2_**|



**Дополнительные требования:**

1. Если отношение длины наибольшей общей подпоследовательности
к длине второго предложения меньше некоего порога, функция возвращает 0.

2. В данной функции ОБЯЗАТЕЛЬНО использовать функцию fill_lcs_matrix (см. Шаг 2).

**Интерфейс:**

```py
def find_lcs_length(first_sentence_tokens: tuple, second_sentence_tokens: tuple, plagiarism_threshold: float) -> int:
  pass
```

### Шаг 5. Нахождение наибольшей общей подпоследовательности

Функция принимает на вход два предложения в виде токенов.
Функция возвращает наибольшую общую подпоследовательность в виде токенов.

Начиная с последнего элемента, функция поднимается к началу по направлениям, заданным первым алгоритмом, и запоминает токены в каждой позиции.
Функция идет:
* по диагонали налево и вверх, если слова с соответствующими индексами равны 
* наверх, если значение в строке с индексом -1 больше значения в столбце с индексом -1
* налево в остальных случаях

**Интерфейс:**

```py
def find_lcs(first_sentence_tokens: tuple, second_sentence_tokens: tuple, lcs_matrix: list) -> tuple:
  pass
```

### Шаг 6. Подсчет доли заимствований для двух предложений

Функция принимает на вход длину наибольшей общей подпоследовательности и предложение в виде токенов, возвращает долю заимствований.

Доля заимствований рассчитывается как отношение длины наибольшей общей подпоследовательности и длины "подозрительного" предложения.

**Интерфейс:**

```py
def calculate_plagiarism_score(lcs_length: int, suspicious_sentence_tokens: tuple) -> float:
  pass
```

### Шаг 7. Подсчет доли заимствований для двух текстов (выполнение Шагов 1-6 соответствует 6 баллам)

Функция принимает на вход два текста.
Возвращаемым значением является доля заимствований.

Тексты сравниваются построчно, для каждой пары подсчитывается доля заимствований, например:
* `first_text = [[sent_1], [sent_2], [sent_3], ...]`
* `second_text = [[sent_1_2], [sent_2_2], [sent_3_2], ...]`
* `p1 = plagiarism(sent_1, sent_1_2)`
* `p2 = plagiarism(sent_2, sent_2_2)`
* `p3 = plagiarism(sent_3, sent_3_2)`
* ...
* `p_n = plagiarism(sent_n, sent_n_2)`

Общая доля заимствований рассчитывается как среднее арифметическое полученных долей заимствований,
то есть для текстов из примера выше:
* `p_result = (p1 + p2 + p3 + ... + p_n) / len(second_text)`

Если тексты разной длины, за основу берется содержимое второго ('подозрительного') текста.
Если первый текст меньше, в него добавляются пустые строки до длины второго текста (т.е. чтобы их длины были равны).
Если второй текст меньше, его содержимое сравнивается только с соответствующими строками в первом тексте.


**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать функцию calculate_plagiarism_score (см. Шаг 5).

**Интерфейс:**

```py
def calculate_text_plagiarism_score(original_text_tokens: tuple, suspicious_text_tokens: tuple, plagiarism_threshold=0.3) -> float:
    pass
```

### Шаг 8. Поиск различий в двух предложениях

Функция принимает на вход два предложения и наибольшую общую подпоследовательность, затем сравнивает эти предложения.
Функция возвращает кортеж с индексами изменений. Изменения представляют собой части предложений,
которые не входят в наибольшую общую подпоследовательность.

Для иллюстрации выделим изменения '| |':
* `'its body is covered with | bushy white | fur'`
* `'its body is covered with | shiny black | fur'`

Индексы включают в себя индексы первого слова в измененных частях и индексы последнего слова в измененных частях +1.
Например,
* `first_sentence = ('its', 'body', 'is', 'covered', 'with', 'bushy', 'white', 'fur')`
* `second_sentence = ('its', 'body', 'is', 'covered', 'with', 'shiny', 'black', 'fur')`
* `lcs =  ('its', 'body', 'is', 'covered', 'with', 'fur')`
* Ожидаемое возвращаемое значение –`((5, 7), (5, 7))`,
где первый кортеж соответствует первому предложению, второй – второму.
* Рассмотрим первый кортеж индексов (для первого предложения). Индекс первого слова `'bushy'` в изменении `'bushy white'` равен 5,
индекс последнего слова `'white'` в изменении равен 6. Соответственно кортеж представляет собой пару индексов (5, 6+1) -> (5, 7)

Обратите внимание, что если отличное слово стоит в конце, индекс изменения будет равен длине предложения.
Также в предложении может присутствовать несколько изменений.

**Интерфейс:**

```py
def find_diff_in_sentence(original_sentence_tokens: tuple, suspicious_sentence_tokens: tuple, lcs: tuple) -> tuple:
    pass
```

### Шаг 9. Сбор статистики по двум текстам

Функция принимает на вход два текста.
Собирает статистику для всех пар предложений в тексте в виде словаря:

```
 {
 'text_plagiarism': int,
 'sentence_plagiarism': list,
 'sentence_lcs_length': list,
 'difference_indexes': list
 }
```

Ключу `text_plagiarism` соответствует значение – доля заимствований по тексту.

Ключу `sentence_plagiarism` – список с долями заимствований для каждой сравниваемой пары предложений.

Ключу `sentence_lcs_length` – список с значениями длин lcs для каждой сравниваемой пары предложений.

Ключу `difference_indexes` – список с индексами изменений для каждой сравниваемой пары предложений.

Если тексты разной длины, за основу берется содержимое второго ('подозрительного') текста.
Если первый текст меньше, в него добавляются пустые строки до длины второго текста (т.е. чтобы их длины были равны).
Если второй текст меньше, его содержимое сравнивается только с соответствующими строками в первом тексте.

Например,
* `first_text = (('i', 'have', 'a', 'cat'), ('his', 'name', 'is', 'bruno'))`
* `second_text = (('i', 'have', 'a', 'cat'), ('his', 'name', 'is', 'paw'))`

```
{
'text_plagiarism': 0.875,
'sentence_plagiarism': [1.0, 0.75],
'sentence_lcs_length': [4, 3],
'difference_indexes': [((), ()), ((3, 4), (3, 4))]
}
```


**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать функции
find_lcs_length (см. Шаг 3), calculate_plagiarism_score (см. Шаг 5), find_diff_in_sentence (см. Шаг 7).

**Интерфейс:**

```py
def accumulate_diff_stats(original_text_tokens: tuple, suspicious_text_tokens: tuple, plagiarism_threshold=0.3) -> dict:
    pass
```

### Шаг 10. Поиск различий в файлах (выполнение Шагов 1-9 соответствует 8 баллам)

Функция выводит на экран построчный отчет по файлам и среднюю долю заимствований в следующем формате:
```
- исходное предложение (с изменениями, выделенными |, если такие имеются)
+ проверяемое предложение (с изменениями, выделенными |, если такие имеются)

lcs = ..., plagiarism = ...%

Text average plagiarism (words): ...%
```

Например,
```
- i have a cat
+ i have a cat

lcs = 4, plagiarism = 100.0%

- its body is covered with | bushy white | fur
+ its body is covered with | shiny black | fur

lcs = 6, plagiarism = 75.0%

Text average plagiarism (words): 87.5%
```

Если тексты разной длины, за основу берется содержимое второго ('подозрительного') текста.
Если первый текст меньше, в него добавляются пустые строки до длины второго текста (т.е. чтобы их длины были равны).
Если второй текст меньше, его содержимое сравнивается только с соответствующими строками в первом тексте.

**Интерфейс:**

```py
def create_diff_report(original_text_tokens: tuple, suspicious_text_tokens: tuple, accumulated_diff_stats: dict) -> str:
    pass
```

### Шаг 11. Работа с большими файлами (выполнение Шагов 1-10 соответствует 10 баллам)

Получите среднюю долю заимствований сравнивая большие файлы.
Оптимизируйте алгоритм расчета длины наибольшей общей подпоследовательности. 

### Литература для пытливых умов

1. [Ссылка на Википедию](https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B8%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B0%D1%8F_%D0%BE%D0%B1%D1%89%D0%B0%D1%8F_%D0%BF%D0%BE%D0%B4%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C#:~:text=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%20%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F%20%D0%BD%D0%B0%D0%B8%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B5%D0%B9%20%D0%BE%D0%B1%D1%89%D0%B5%D0%B9%20%D0%BF%D0%BE%D0%B4%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8,%D0%BA%D0%B0%D0%BA%20%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%20%D0%B2%D1%81%D0%B5%D1%85%20%D0%BD%D0%B0%D0%B8%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85%20%D0%BF%D0%BE%D0%B4%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9)
2. [Lecture notes](https://www.ics.uci.edu/~eppstein/161/960229.html)
