# Лабораторная работа №2

## Дано

1. Два текста на английском языке
2. Необходимо посчитать степень заимствований из первого текста во втором тексте.
За основу берется алгоритм поиска наибольшей общей подпоследовательности (longest common subsequence)


## Терминология
Последовательность представляет собой упорядоченный набор элементов. 

Возьмем две последовательности: `x = ['the', 'cat', 'is', 'sleeping']` и `y = ['the', 'dog', 'is', 'running']`

`z` — подпоследовательность `x` в том случае, если существует строго возрастающий набор индексов элементов `x`,
из которых получается `z`. Например, для `x = ['the', 'cat', 'is', 'sleeping']`, `z = ['the', 'sleeping']`.

Общей подпоследовательностью для `x` и `y` считаем такую последовательность `z`,
которая является одновременно подпоследовательностью `x` и подпоследовательностью `y`.

Наибольшая общая подпоследовательность — это общая подпоследовательность с максимальной длиной.
Далее будем использовать сокращение `LCS`.

Например, для `x = ['the', 'cat', 'is', 'sleeping']` и `y = ['the', 'dog', 'is', 'running']`,
`LCS(x, y)= ['the', 'is']`.

## Что надо сделать

В рамках лабораторной работы №2 требуется разработать алгоритм поиска наибольшей общей подпоследовательности
и использовать его для выявления плагиата.


### Шаг 1. Токенизация текста

Функция принимает на вход текст и возвращает кортеж предложений с токенами.

Если на вход подается некорректное значение, возвращается пустой кортеж.

Например, text = 'I have a cat.\nHis name is Bruno'
--> (('i', 'have', 'a', 'cat'), ('his', 'name', 'is', 'bruno'))

**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать функцию `tokenize` из модуля `tokenizer`.

**Интерфейс:**

```py
def tokenize_by_lines(text: str) -> tuple:
  pass
```


### Шаг 2. Создание матрицы решений

Функция принимает на вход количество строк и столбцов и создает матрицу.
Функция должна возвращать объект типа list - список, состоящий из списков заданного размера.
Все элементы списков - нули.

Если на вход подаются некорректные значения, возвращается пустой список.

Например, матрица 2x2 – [[0, 0], [0, 0]]

**Интерфейс:**

```py
def create_zero_matrix(rows: int, columns: int) -> list:
  pass
```

### Шаг 3. Заполнение матрицы решений

На данном шаге применяется алгоритм поиска наибольшей общей подпоследовательности.

Функция принимает на вход два предложения в виде токенов.
Возвращаемым значением является заполненная матрица решений.

Если на вход подаются некорректные токены, возвращается пустой список.

Правило заполнения каждой ячейки матрицы:

<img src="https://latex.codecogs.com/gif.latex?LCS-length(X_i,&space;Y_j)&space;=&space;\left\{\begin{matrix}0&space;&&space;i=0\:&space;or\:&space;j=0\\&space;LCS-length(X__{i-1},&space;Y_{j-1})&space;&plus;&space;1&space;&&space;i,&space;j>0\:&space;and\:&space;x_i=y_i&space;\\&space;max\left&space;\{LCS-length(X__{i},&space;Y_{j-1}),&space;LCS-length(X__{i-1},&space;Y_{j})&space;\right&space;\}&space;&&space;i,&space;j>0\:&space;and\:&space;x_i\neq&space;y_i&space;\end{matrix}\right." title="LCS-length(X_i, Y_j) = \left\{\begin{matrix}0 & i=0\: or\: j=0\\ LCS-length(X__{i-1}, Y_{j-1}) + 1 & i, j>0\: and\: x_i=y_i \\ max\left \{LCS-length(X__{i}, Y_{j-1}), LCS-length(X__{i-1}, Y_{j}) \right \} & i, j>0\: and\: x_i\neq y_i \end{matrix}\right." />

> Матрица решений из разбора примера в Разделе "Терминология":

|     |    |     |     |     |     |
|---  |---  |---  |  ---|  ---|  ---|
|     |**0**|**the**|**dog**|**is**|**running**|
|**0**|    0|    0|    0|    0|    0|
|**the**|    0|    1|    1|    1|    1|
|**cat**|    0|    1|    1|    1|    1|
|**is**|    0|    1|    1|    2|    2|
|**sleeping**|    0|    1|    1|    2|    2|


**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать функцию create_zero_matrix (см. Шаг 2).

**Интерфейс:**

```py
def fill_lcs_matrix(first_sentence_tokens: tuple, second_sentence_tokens: tuple) -> list:
  pass
```

### Шаг 4. Расчет длины наибольшей общей подпоследовательности (выполнение Шагов 1-4 соответствует 4 баллам)

Функция принимает на вход два предложения в виде токенов.
Возвращаемым значением является число - длина наибольшей общей подпоследовательности.

Если на вход подаются некорректные значения, возвращается `-1`.

Длина наибольшей общей подпоследовательности находится на пересечении последней строки и последнего столбца.

|     |    |     |     |     |     |
|---  |---  |---  |  ---|  ---|  ---|
|     |**0**|**the**|**dog**|**is**|**running**|
|**0**|    0|    0|    0|    0|    0|
|**the**|    0|    1|    1|    1|    1|
|**cat**|    0|    1|    1|    1|    1|
|**is**|    0|    1|    1|    2|    2|
|**sleeping**|    0|    1|    1|    2|    **_2_**|



**Дополнительные требования:**

1. Если отношение длины наибольшей общей подпоследовательности
к длине второго предложения меньше порога `plagiarism_threshold`, функция возвращает 0.

2. В данной функции ОБЯЗАТЕЛЬНО использовать функцию fill_lcs_matrix (см. Шаг 3).

**Интерфейс:**

```py
def find_lcs_length(first_sentence_tokens: tuple, second_sentence_tokens: tuple, plagiarism_threshold: float) -> int:
  pass
```

### Шаг 5. Нахождение наибольшей общей подпоследовательности

Функция принимает на вход два предложения в виде токенов.
Функция возвращает наибольшую общую подпоследовательность в виде токенов.

Если на вход подаются некорректные значения, возвращается пустой кортеж.

Начиная с последнего элемента, функция поднимается к началу по направлениям, заданным первым алгоритмом, и запоминает токены в каждой позиции.
Функция идет:
* по диагонали, если слова с соответствующими индексами равны 
* наверх, если значение в строке с индексом -1 больше значения в столбце с индексом -1
* налево в остальных случаях

**Интерфейс:**

```py
def find_lcs(first_sentence_tokens: tuple, second_sentence_tokens: tuple, lcs_matrix: list) -> tuple:
  pass
```

### Шаг 6. Подсчет доли заимствований для двух предложений

Функция принимает на вход длину наибольшей общей подпоследовательности и предложение в виде токенов, возвращает долю заимствований.

Если на вход подаются некорректные значения, возвращается `-1.0`.

Доля заимствований рассчитывается как отношение длины наибольшей общей подпоследовательности и длины "подозрительного" предложения.

**Интерфейс:**

```py
def calculate_plagiarism_score(lcs_length: int, suspicious_sentence_tokens: tuple) -> float:
  pass
```

### Шаг 7. Подсчет доли заимствований для двух текстов (выполнение Шагов 1-7 соответствует 6 баллам)

Функция принимает на вход два текста.
Возвращаемым значением является доля заимствований.

Если на вход подаются некорректные значения, возвращается `-1.0`.

Тексты сравниваются построчно, для каждой пары подсчитывается доля заимствований, например:
* `first_text = ((sent_1), (sent_2), (sent_3), ...)`
* `second_text = ((sent_1_2), (sent_2_2), (sent_3_2), ...)`
* `p1 = plagiarism(sent_1, sent_1_2)`
* `p2 = plagiarism(sent_2, sent_2_2)`
* `p3 = plagiarism(sent_3, sent_3_2)`
* ...
* `p_n = plagiarism(sent_n, sent_n_2)`

Общая доля заимствований рассчитывается как среднее арифметическое полученных долей заимствований,
то есть для текстов из примера выше:
* `p_result = (p1 + p2 + p3 + ... + p_n) / len(second_text)`

**За основу анализа берется содержимое второго ('подозрительного') текста.**

Если первый текст меньше, в него добавляются пустые строки до длины второго текста (т.е. чтобы их длины были равны).

Если второй текст меньше, его содержимое сравнивается только с соответствующими строками в первом тексте.


**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать функцию calculate_plagiarism_score (см. Шаг 6).

**Интерфейс:**

```py
def calculate_text_plagiarism_score(original_text_tokens: tuple, suspicious_text_tokens: tuple, plagiarism_threshold=0.3) -> float:
    pass
```

### Шаг 8. Поиск различий в двух предложениях

Функция принимает на вход два предложения и наибольшую общую подпоследовательность, затем сравнивает эти предложения.
Функция возвращает кортеж с индексами изменений. Изменения представляют собой части предложений,
которые не входят в наибольшую общую подпоследовательность.

Если на вход подаются некорректные значения, возвращается пустой кортеж.

Для иллюстрации выделим изменения '| |':
* `'| her | body is covered with | bushy white | fur'`
* `'| his | body is covered with | shiny black | fur'`

**Индексы включают в себя индексы первого слова в измененных частях и индексы последнего слова в измененных частях +1.**

Например,
* `first_sentence = ('her', 'body', 'is', 'covered', 'with', 'bushy', 'white', 'fur')`
* `second_sentence = ('his', 'body', 'is', 'covered', 'with', 'shiny', 'black', 'fur')`
* `lcs =  ('body', 'is', 'covered', 'with', 'fur')`
* Ожидаемое возвращаемое значение –`((0, 1, 5, 7), (0, 1, 5, 7))`,
где первый кортеж соответствует первому предложению, второй – второму.
* Рассмотрим первый кортеж индексов (для первого предложения). Индекс первого и одновременно последнего в изменении слова `'her'` равен `0`.
Индекс первого слова `'bushy'` в изменении `'bushy white'` равен 5,
индекс последнего слова `'white'` в изменении равен 6. Соответственно кортеж представляет собой набор индексов `(0, 0+1, 5, 6+1)` -> `(0, 1, 5, 7)`

Обратите внимание, что если отличное слово стоит в конце, индекс изменения будет равен длине предложения.
Также в предложении может присутствовать несколько изменений.

**Интерфейс:**

```py
def find_diff_in_sentence(original_sentence_tokens: tuple, suspicious_sentence_tokens: tuple, lcs: tuple) -> tuple:
    pass
```

### Шаг 9. Сбор статистики по двум текстам

Функция принимает на вход два текста.
Собирает статистику для всех пар предложений в тексте в виде словаря:

```
 {
 'text_plagiarism': int,
 'sentence_plagiarism': list,
 'sentence_lcs_length': list,
 'difference_indexes': list
 }
```

Ключу `text_plagiarism` соответствует значение – доля заимствований по тексту.

Ключу `sentence_plagiarism` – список с долями заимствований для каждой сравниваемой пары предложений.

Ключу `sentence_lcs_length` – список с значениями длин lcs для каждой сравниваемой пары предложений.

Ключу `difference_indexes` – список с индексами изменений для каждой сравниваемой пары предложений.

**За основу анализа берется содержимое второго ('подозрительного') текста.**

Если первый текст меньше, в него добавляются пустые строки до длины второго текста (т.е. чтобы их длины были равны).

Если второй текст меньше, его содержимое сравнивается только с соответствующими строками в первом тексте.

Если на вход подаются некорректные значения, возвращается пустой словарь.

Например,
* `first_text = (('i', 'have', 'a', 'cat'), ('his', 'name', 'is', 'bruno'))`
* `second_text = (('i', 'have', 'a', 'cat'), ('his', 'name', 'is', 'paw'))`

```
{
'text_plagiarism': 0.875,
'sentence_plagiarism': [1.0, 0.75],
'sentence_lcs_length': [4, 3],
'difference_indexes': [((), ()), ((3, 4), (3, 4))]
}
```


**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать функции
find_lcs_length (см. Шаг 4), calculate_plagiarism_score (см. Шаг 6), find_diff_in_sentence (см. Шаг 8).

**Интерфейс:**

```py
def accumulate_diff_stats(original_text_tokens: tuple, suspicious_text_tokens: tuple, plagiarism_threshold=0.3) -> dict:
    pass
```

### Шаг 10. Поиск различий в файлах (выполнение Шагов 1-10 соответствует 8 баллам)

Функция выводит на экран построчный отчет по файлам и среднюю долю заимствований в следующем формате:
```
- исходное предложение (с изменениями, выделенными |, если такие имеются)
+ проверяемое предложение (с изменениями, выделенными |, если такие имеются)

lcs = ..., plagiarism = ...%

Text average plagiarism (words): ...%
```

Если на вход подаются некорректные значения, возвращается пустая строка.

Например,
```
- i have a cat
+ i have a cat

lcs = 4, plagiarism = 100.0%

- its body is covered with | bushy white | fur
+ its body is covered with | shiny black | fur

lcs = 6, plagiarism = 75.0%

Text average plagiarism (words): 87.5%
```

**За основу анализа берется содержимое второго ('подозрительного') текста.**

Если первый текст меньше, в него добавляются пустые строки до длины второго текста (т.е. чтобы их длины были равны).

Если второй текст меньше, его содержимое сравнивается только с соответствующими строками в первом тексте.

**Интерфейс:**

```py
def create_diff_report(original_text_tokens: tuple, suspicious_text_tokens: tuple, accumulated_diff_stats: dict) -> str:
    pass
```

### Шаг 11. Оптимизация алгоритма поиска длины наибольшей общей подпоследовательности 

Оптимизируйте алгоритм расчета длины наибольшей общей подпоследовательности.
При поиске длины подпоследовательности запрещено хранить всю матрицу изменений.

> Для получения длины наибольшей общей подпоследовательности на каждом шаге сравнения
> достаточно знать текущую и предыдущую строки матрицы.


**Интерфейс:**

```py
def find_lcs_length_optimized(first_sentence_tokens: tuple, second_sentence_tokens: tuple,
                              plagiarism_threshold: float) -> int:
    pass
```

### Шаг 12. Обработка больших файлов

При оценке на плагиат могут встретиться два больших файла, которые не помещаются в оперативную память.
На этом шаге предлагается подумать и предложить программные оптимизации обработки больших файлов.

Пример такого файла: [data.txt](https://drive.google.com/drive/folders/1WUvCKNvL0JFRJLfT_yXdANv7bOKB_CUx?usp=sharing)

> 1. Считывание и токенизация текстов производятся по частям
> 2. Файл рассматривается как единый массив текста (одно большое предложение)
> 3. Хранение и сравнение строк в Python затратно в отличие от чисел.
     Можно ли вместо набора токенов использовать набор идентификаторов этих токенов?
> 4. Создание и хранение кортежей менее затратно, чем создание и хранение списков
> 5. Явное создание кортежей медленее, чем использование генераторов для создания кортежей

Функция `tokenize_big_file` принимает на вход путь до текстового файла и возвращает кортеж из чисел.

```py
def tokenize_big_file(path_to_file: str) -> tuple:
    pass
```

### Шаг 13. Сравнение больших файлов (выполнение Шагов 1-13 соответствует 10 баллам)

Получите долю заимствований из первого **очень большого** текста во втором **очень большом** тексте.
Продемонстрируйте использование функций из Шагов 11 – 12 для расчета доли заимствований [data.txt (original) и data_2.txt (suspicious)](https://drive.google.com/drive/folders/1WUvCKNvL0JFRJLfT_yXdANv7bOKB_CUx?usp=sharing) в модуле `start.py`.
Для этого данные файлы надо скачать и положить их в папку `lab_2`

### Литература для пытливых умов

1. [Ссылка на Википедию](https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B8%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B0%D1%8F_%D0%BE%D0%B1%D1%89%D0%B0%D1%8F_%D0%BF%D0%BE%D0%B4%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C#:~:text=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%20%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F%20%D0%BD%D0%B0%D0%B8%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B5%D0%B9%20%D0%BE%D0%B1%D1%89%D0%B5%D0%B9%20%D0%BF%D0%BE%D0%B4%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8,%D0%BA%D0%B0%D0%BA%20%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%20%D0%B2%D1%81%D0%B5%D1%85%20%D0%BD%D0%B0%D0%B8%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85%20%D0%BF%D0%BE%D0%B4%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9)
2. [Lecture notes](https://www.ics.uci.edu/~eppstein/161/960229.html)
3. Одним из оптимальных алгоритмов поиска наибольшей общей подпоследовательности является
   [алгоритм Хишберга](https://imada.sdu.dk/~rolf/Edu/DM823/E16/Hirschberg.pdf).
   Шаг 11 является предпосылкой к реализации этого алгоритма.
